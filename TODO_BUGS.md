# To - Do
---

## scraping.ipynb

- [x]  Add multiple DBs to scrape save
- [x]  Create main function for CLI
- [x]  Figure out argparse
- [ ]  Do I actually need this file?



## scraping.py

- [ ] Add logging
- [ ] Testing?
- [ ]  Set Linux Cron job for auto scrape


## scraper_config.json

- [ ]  Simple format for only scraper config
- [ ]  Update to include other config parameters, possibly preprocessor and model dictionaries
- [ ]  Most likely rename file to generic config file.


## ds_workflow.ipynb

- [ ]  finish data loader
- [ ]  create better functions using `05_Functions` as template
- [ ]  Functions need to use combinatorics (?) to compare only two subreddits at a time for certain analyses
- [ ]  This file should eventually become a `dataloader.py` file and be imported into DS workflows



## Project Files

- [ ]  Create multiple DS workflow notebooks for use cases
- [ ]  Create and install multiple DBs to make functions, ummm function.
- [ ]  Create logging file(s)
- [ ] Take code out of `code` folder and restructure project


## Additions

- [ ]  
- [ ]  Dump data into MongoDB also?
- [ ]  Find more sources of data
- [ ]  SQL Stats


## Problems / Issues / Lack of Knowledge

- [ ] Functions for engineering / bare code for EDA and analysis?
- [ ] Copy of a slice
- [ ] UNIT TESTING
- [ ] .ipynb vs .py - Keep them both? `demo.ipynb`?  


# Bugs

## scraping.py

- [ ] scraper returns less than 10 posts when sort is set to anything other than 'new'
- [ ] 

