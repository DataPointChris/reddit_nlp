{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thorough Gridsearch Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code to easily add a model and preprocessor(s) and gridsearch through every possible combination to find the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future:\n",
    "Compare bagging, boosting, gradient, with base model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, validation_curve\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import CONFIG\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import databases\n",
    "from util import dataloader\n",
    "from util import grid_models\n",
    "from util.reddit_functions import Labeler\n",
    "from util.reddit_functions import plot_confusion_matrix\n",
    "from util.grid_models import custom_stop_words, get_random_class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_random_class_labels(8)\n",
    "print(labels)\n",
    "\n",
    "df = dataloader.data_selector(labels, data_source='sqlite')\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title']\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO ### use scikit-learn labeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler = Labeler()\n",
    "labeler.fit(y)\n",
    "y = labeler.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = {\n",
    "    'preprocessor': TfidfVectorizer(stop_words=custom_stop_words),\n",
    "    'params': {\n",
    "        \"prep__ngram_range\": [(1, 2)],\n",
    "        \"prep__max_df\": [.9],\n",
    "        \"prep__use_idf\": [True],\n",
    "        \"prep__norm\": [\"l2\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = {\n",
    "    'clf': LogisticRegression(max_iter=1000),\n",
    "    'params': {\n",
    "        \"clf__C\": [.01, .1, 1, 5]\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = {\n",
    "    'clf': XGBClassifier(n_jobs=-1),\n",
    "    'params': {\n",
    "        \"clf__max_depth\": [3, 5, 10, 20, 50],\n",
    "        \"clf__learning_rate\": np.linspace(.001, .99, 5),\n",
    "        \"clf__n_estimators\": [50, 100, 200],\n",
    "        \"clf__objective\": ['binary:logistic', 'multi:softprob'],\n",
    "        \"clf__booster\": ['gbtree', 'gblinear', 'dart'],\n",
    "        \"clf__gamma\": np.linspace(0, 1, 5),\n",
    "        \"clf__subsample\": np.linspace(.5, 1, 5),\n",
    "        \"clf__reg_alpha\": np.linspace(0, 1, 5),\n",
    "        \"clf__reg_lambda\": np.linspace(0, 1, 5),\n",
    "        \"clf__importance_type\": ['gain', 'weight', 'cover', 'total_gain', 'total_cover'],\n",
    "        \"clf__hidden_layer_sizes\": [10, 20, 30, 40, 50],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_orig = {\n",
    "    'clf': XGBClassifier(n_jobs=-1),\n",
    "    'params': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = {\n",
    "    'clf': RandomForestClassifier(),\n",
    "    'params': {\n",
    "        \"clf__n_estimators\": [200, 300]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "onevrest = {\n",
    "    'clf': OneVsRestClassifier(RandomForestClassifier()),\n",
    "    'params': {\n",
    "        \"clf__estimator__n_estimators\": [200, 300]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_model(preprocessor, classifier, cv=3, verbose=1):\n",
    "    '''\n",
    "    Takes a dictionary with params and outputs a fitted model\n",
    "    '''\n",
    "    pipe = Pipeline(\n",
    "    [('prep', preprocessor.get('preprocessor')),\n",
    "     ('clf', classifier.get('clf'))])\n",
    "    \n",
    "    pipe_params = dict()\n",
    "    pipe_params.update(preprocessor.get('params'))\n",
    "    pipe_params.update(classifier.get('params'))\n",
    "    \n",
    "    model = GridSearchCV(pipe, param_grid=pipe_params, cv=cv, verbose=verbose, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for estimator in [xgb_orig, xgb]:\n",
    "    \n",
    "    model = build_and_train_model(preprocessor=tfidf, classifier=estimator, verbose=5)\n",
    "    \n",
    "    date = str(datetime.datetime.now().strftime('%Y-%m-%d_%H%M'))\n",
    "    estimator_name = type(model.estimator.named_steps.clf).__name__\n",
    "    joblib_file = f'{estimator_name}_best_model_{date}.pkl'\n",
    "    joblib.dump(model, CONFIG.DATA_DIR / joblib_file)\n",
    "    \n",
    "    print(f'Train Score: {model.score(X_train, y_train)}')\n",
    "    print(f'Test Score: {model.score(X_test, y_test)}')\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "        print(f'AUC Score: {roc_auc_score(y_test, y_proba, multi_class=\"ovr\")}')\n",
    "        \n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    plot_confusion_matrix(model, y_test, y_pred, classes=labeler.classes_)\n",
    "    plt.savefig(CONFIG.DATA_DIR / f'{estimator_name}_confusion_matrix_{date}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
