{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/sanjeevai/disaster-response-pipeline/blob/master/models/train_classifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high resolution notebooks\n",
    "%config InlineBackend.figure_format ='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "import wordcloud\n",
    "import time\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from glob import glob\n",
    "import databases\n",
    "import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud.WordCloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cloud(X):\n",
    "    '''\n",
    "    Uses X value of data, which should be text columns\n",
    "    \n",
    "    Returns:\n",
    "    image\n",
    "    '''\n",
    "\n",
    "    wc = wordcloud.WordCloud(max_words=50, \n",
    "                             width=700, \n",
    "                             height=400, \n",
    "                             background_color='white',\n",
    "                            )\n",
    "\n",
    "    \n",
    "\n",
    "    cloud = wc.generate(X.str.cat())\n",
    "\n",
    "    return cloud.to_image()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_list = ['css', 'html', 'javascript', 'php', 'perl', 'java', 'datascience', 'machinelearning', 'etl', 'python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subreddit_list = ['datascience','sql']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to SQLite DB successful\n",
      "No data for javascript\n",
      "No data for php\n",
      "No data for perl\n",
      "No data for java\n",
      "No data for etl\n",
      "No data for python\n"
     ]
    }
   ],
   "source": [
    "df = dataloader.data_selector(subreddit_list, 'sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic dict to make sure: {'datascience': 0, 'html': 1, 'css': 2, 'machinelearning': 3}\n"
     ]
    }
   ],
   "source": [
    "df = dataloader.subreddit_encoder(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>date</th>\n",
       "      <th>sub_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3119</td>\n",
       "      <td>Assistance with multiple “if else” statements</td>\n",
       "      <td>html</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1341</td>\n",
       "      <td>What does a day in the life of your work entail?</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Awesome data science interview resources</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5305</td>\n",
       "      <td>[R] How Good is the Bayes Posterior in Deep Ne...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2408</td>\n",
       "      <td>Statistical Tests Across Many Variables</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1499</td>\n",
       "      <td>New to Kaggle -can you add to competition data...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2999</td>\n",
       "      <td>How do I allow spaces in my text?</td>\n",
       "      <td>html</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>Admin rights for my website?</td>\n",
       "      <td>html</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>961</td>\n",
       "      <td>Should you do feature engineering first, hyper...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6268</td>\n",
       "      <td>should I get Ubuntu or Linux Mint?</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title        subreddit  \\\n",
       "3119      Assistance with multiple “if else” statements             html   \n",
       "1341   What does a day in the life of your work entail?      datascience   \n",
       "9              Awesome data science interview resources      datascience   \n",
       "5305  [R] How Good is the Bayes Posterior in Deep Ne...  machinelearning   \n",
       "2408            Statistical Tests Across Many Variables      datascience   \n",
       "1499  New to Kaggle -can you add to competition data...      datascience   \n",
       "2999                  How do I allow spaces in my text?             html   \n",
       "3160                       Admin rights for my website?             html   \n",
       "961   Should you do feature engineering first, hyper...      datascience   \n",
       "6268                 should I get Ubuntu or Linux Mint?      datascience   \n",
       "\n",
       "            date  sub_code  \n",
       "3119  2020-03-10         1  \n",
       "1341  2020-03-10         0  \n",
       "9     2020-03-10         0  \n",
       "5305  2020-03-10         3  \n",
       "2408  2020-03-10         0  \n",
       "1499  2020-03-10         0  \n",
       "2999  2020-03-10         1  \n",
       "3160  2020-03-10         1  \n",
       "961   2020-03-10         0  \n",
       "6268  2020-03-10         0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title']\n",
    "y = df['sub_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_titles = my_stops.union(df.subreddit.unique())\n",
    "useless_words = my_stops.union(['using', 'help', 'new', 'data', 'science','learning'])\n",
    "\n",
    "custom_stop_words = ENGLISH_STOP_WORDS.union(subreddit_titles, useless_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('count_vec', CountVectorizer()), ('lr', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "                'count_vec__max_features': [3000,4000,5000,6000,8000],\n",
    "                'count_vec__max_df': [.3,.4,.5],\n",
    "                'count_vec__ngram_range': [(1,2),(1,3),(1,4)],\n",
    "                'count_vec__stop_words': [custom_stop_words],\n",
    "                'count_vec__min_df': [4,5,6],\n",
    "                'lr__penalty': ['l1','l2'],\n",
    "                'lr__C': [.01, .1, 1]\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(pipe, param_grid=pipe_params, cv=5, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    2.5s finished\n",
      "/Users/chris/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/chris/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Modeling Score: 0.7588163761653831\n",
      "Train Score: 0.8611674098094853\n",
      "Test Score: 0.7872340425531915\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Modeling Score: {model.best_score_}')\n",
    "\n",
    "print(f'Train Score: {model.score(X_train, y_train)}')\n",
    "\n",
    "print(f'Test Score: {model.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model is GridSearchCV\n",
    "# best_estimator is Pipeline\n",
    "# named_steps is the steps in the pipeline\n",
    "# count_vec is the FITTED \n",
    "\n",
    "features_data = model.best_estimator_.named_steps.count_vec.transform(X).toarray()\n",
    "features_columns = model.best_estimator_.named_steps.count_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(data=features_data, columns=features_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01</th>\n",
       "      <th>01 mar</th>\n",
       "      <th>02</th>\n",
       "      <th>02 feb</th>\n",
       "      <th>08</th>\n",
       "      <th>08 mar</th>\n",
       "      <th>09</th>\n",
       "      <th>09 feb</th>\n",
       "      <th>10</th>\n",
       "      <th>10 open</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>yikes</th>\n",
       "      <th>young</th>\n",
       "      <th>young aspiring</th>\n",
       "      <th>young changing</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youtube channels</th>\n",
       "      <th>zero</th>\n",
       "      <th>zero experience</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6574</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6576</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6577</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6578</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6579 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      01  01 mar  02  02 feb  08  08 mar  09  09 feb  10  10 open  ...  yes  \\\n",
       "0      0       0   0       0   0       0   0       0   0        0  ...    0   \n",
       "1      0       0   0       0   0       0   0       0   0        0  ...    0   \n",
       "2      0       0   0       0   0       0   0       0   0        0  ...    0   \n",
       "3      0       0   0       0   0       0   0       0   0        0  ...    0   \n",
       "4      0       0   0       0   0       0   0       0   0        0  ...    0   \n",
       "...   ..     ...  ..     ...  ..     ...  ..     ...  ..      ...  ...  ...   \n",
       "6574   0       0   0       0   0       0   0       0   0        0  ...    0   \n",
       "6575   0       0   0       0   0       0   0       0   0        0  ...    0   \n",
       "6576   0       0   0       0   0       0   0       0   0        0  ...    0   \n",
       "6577   0       0   0       0   0       0   0       0   0        0  ...    0   \n",
       "6578   0       0   0       0   0       0   0       0   0        0  ...    0   \n",
       "\n",
       "      yikes  young  young aspiring  young changing  youtube  youtube channels  \\\n",
       "0         0      0               0               0        0                 0   \n",
       "1         0      0               0               0        0                 0   \n",
       "2         0      0               0               0        0                 0   \n",
       "3         0      0               0               0        0                 0   \n",
       "4         0      0               0               0        0                 0   \n",
       "...     ...    ...             ...             ...      ...               ...   \n",
       "6574      0      0               0               0        0                 0   \n",
       "6575      0      0               0               0        0                 0   \n",
       "6576      0      0               0               0        0                 0   \n",
       "6577      0      0               0               0        0                 0   \n",
       "6578      0      0               0               0        0                 0   \n",
       "\n",
       "      zero  zero experience  zoom  \n",
       "0        0                0     0  \n",
       "1        0                0     0  \n",
       "2        0                0     0  \n",
       "3        0                0     0  \n",
       "4        0                0     0  \n",
       "...    ...              ...   ...  \n",
       "6574     0                0     0  \n",
       "6575     0                0     0  \n",
       "6576     0                0     0  \n",
       "6577     0                0     0  \n",
       "6578     0                0     0  \n",
       "\n",
       "[6579 rows x 5000 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_common = features.sum().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Combined Most Common Words')\n",
    "base_common.plot.barh();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=len(df.subreddit.unique()), figsize=(15,6*len(df.subreddit.unique())))\n",
    "\n",
    "for subplot_idx, sub in enumerate(df.subreddit.unique()):\n",
    "    topic_features = features.loc[df['subreddit'] == sub, :]\n",
    "    topic_features_to_plot = topic_features[base_common.index].sum()\n",
    "    \n",
    "    topic_features_to_plot.plot(kind='barh', ax=ax[subplot_idx])\n",
    "    max_occurence = features.sum().max()\n",
    "    ax[subplot_idx].set_xlim(0,max_occurence)\n",
    "    ax[subplot_idx].set_title(sub.upper(), fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo for this section\n",
    "\n",
    "1. make each of these functions only take two "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15,6))\n",
    "df[base_common.index].sum().plot.barh(ax=ax1, title='Science', color='navy')\n",
    "ax1.set_xlim(0,2800)\n",
    "ax2.set_xlim(0,2800)\n",
    "tech[base_common.index].sum().plot.barh(ax=ax2, title='Technology', color='orange');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "\n",
    "\n",
    "groups = features.groupby(df['subreddit']).sum()[base_common.index].T.head(20)\n",
    "plt.title('20 Most Common Words', fontsize=20)\n",
    "\n",
    "groups.plot.bar(\n",
    "                ax=ax,\n",
    "                width=.8,\n",
    "                # set style for colors instead of have to choose individually\n",
    "                color=['gray','navy','orange','purple','red'],\n",
    "                fontsize=15,\n",
    "                );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Clouds!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_cloud(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 6*len(trimmed_list)))\n",
    "for i, sub in enumerate(trimmed_list):\n",
    "    ax = fig.add_subplot(len(trimmed_list),1,i+1)\n",
    "    cloud = make_cloud(X=df[df['subreddit'] == sub]['title'])\n",
    "    \n",
    "\n",
    "    ax.set_title(topic.upper(), fontdict={'fontsize': 24})\n",
    "    ax.imshow(cloud)\n",
    "    ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do for this section\n",
    "\n",
    "1. Confusion Matrix for all selected Topics\n",
    "2. Make a function that will compare all topics in 1x1 fasion, find combinatorics or whatever Python library\n",
    "3. Output each of the comparisons if a list of more than 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions = lr_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cm = confusion_matrix(y_test, lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_confusion_df = pd.DataFrame(lr_cm, columns=topics, index=topics)\n",
    "\n",
    "lr_confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = lr_cm.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_spec = tn / (tn + fp)\n",
    "lr_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity/Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_sens = tp / (tp +fn)\n",
    "lr_sens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_auc = roc_auc_score(y_test, lr_predictions)\n",
    "lr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = lr_grid.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not multiclass\n",
    "lr_fpr, lr_tpr, lr_thresholds = roc_curve(y_test, lr_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(lr_fpr, lr_tpr, label=f'ROC curve (area = {lr_auc})', color='r', marker='D')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)', size=16)\n",
    "plt.ylabel('True Positive Rate (Sensitivity)', size=16)\n",
    "plt.title('ROC Curve Logistic Regression', size=20)\n",
    "plt.legend(fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create figure.\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "# Create histogram of observations.\n",
    "plt.hist(lr_probs, bins=25, color='b')\n",
    "\n",
    "# Label axes.\n",
    "plt.title('Distribution of P(Outcome = 1)', fontsize=22)\n",
    "plt.ylabel('Frequency', fontsize=18)\n",
    "plt.xlabel('Predicted Probability that Outcome = 1', fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure.\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "# Create two histograms of observations.\n",
    "hst0 = plt.hist(lr_probs[y_test == 0],\n",
    "         bins=25,\n",
    "         color='b',\n",
    "         alpha = 0.6,\n",
    "         label='Technology',)\n",
    "\n",
    "hst1 = plt.hist(lr_probs[y_test == 1],\n",
    "         bins=25,\n",
    "         color='orange',\n",
    "         alpha = 0.6,\n",
    "         label='Science')\n",
    "\n",
    "# Add vertical line at P(Outcome = 1) = 0.5.\n",
    "plt.vlines(x=0.5,\n",
    "           ymin = 0,\n",
    "           ymax = max(hst1[0].max(), hst0[0].max()), # Max of the two highest respective hist values\n",
    "           color='r',\n",
    "           linestyle = '--')\n",
    "\n",
    "# Label axes.\n",
    "plt.title('Distribution of P(Science)', fontsize=22)\n",
    "plt.ylabel('Frequency', fontsize=18)\n",
    "plt.xlabel('Predicted Probability', fontsize=18)\n",
    "\n",
    "# Create legend.\n",
    "plt.legend(fontsize=20);\n",
    "\n",
    "# Thanks to Matt Brems for the colorful graphs! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_feats = lr_grid.best_estimator_.named_steps['tfidf'].get_feature_names()\n",
    "\n",
    "lr_catcher = lr_grid.best_estimator_.named_steps['lr']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.title('Feature Importance (Coefficients)', fontsize=20)\n",
    "plt.ylabel('Features', fontsize=18)\n",
    "plt.xlabel('(Abs) Coefficients', fontsize=18)\n",
    "\n",
    "coef_df = pd.DataFrame(lr_catcher.coef_, columns=lr_feats).T\n",
    "coef_df['abs_coef'] = coef_df[0].abs()\n",
    "coef_df.sort_values('abs_coef', ascending=False)[0].head(15).plot(kind='barh');\n",
    "\n",
    "# coef_kill = coef_df.sort_values('abs_coef', ascending=False)[0].head(500).index\n",
    "\n",
    "# coef_kill\n",
    "\n",
    "\n",
    "# my_stops.extend(coef_kill)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
