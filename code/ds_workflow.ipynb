{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/sanjeevai/disaster-response-pipeline/blob/master/models/train_classifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "import wordcloud\n",
    "import time\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from glob import glob\n",
    "import databases\n",
    "import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cloud(X):\n",
    "    '''\n",
    "    Uses X value of data, which should be text columns\n",
    "    '''\n",
    "\n",
    "    wc = wordcloud.WordCloud(max_words=50, \n",
    "                             width=700, \n",
    "                             height=400, \n",
    "                             background_color='white',\n",
    "                            )\n",
    "\n",
    "    \n",
    "\n",
    "    cloud = wc.generate(X.str.cat())\n",
    "\n",
    "    return cloud.to_image()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_list = ['css', 'html', 'javascript', 'php', 'perl', 'java', 'datascience', 'machinelearning', 'etl', 'python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subreddit_list = ['datascience','sql']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to SQLite DB successful\n",
      "No data for javascript\n",
      "No data for php\n",
      "No data for perl\n",
      "No data for java\n",
      "No data for etl\n",
      "No data for python\n"
     ]
    }
   ],
   "source": [
    "df = dataloader.data_selector(subreddit_list, 'sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic dict to make sure: {'datascience': 0, 'html': 1, 'css': 2, 'machinelearning': 3}\n"
     ]
    }
   ],
   "source": [
    "df = dataloader.subreddit_encoder(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>date</th>\n",
       "      <th>sub_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2667</td>\n",
       "      <td>How many years of data is sufficient for an an...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>Association of store's names</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6503</td>\n",
       "      <td>Do you leave your EDA in notebooks?</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6526</td>\n",
       "      <td>big data no budget best practice</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4342</td>\n",
       "      <td>Is it possible to code a wordpress theme (veni...</td>\n",
       "      <td>css</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2490</td>\n",
       "      <td>This made me laugh harder than it should lol....</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>489</td>\n",
       "      <td>It's been 2 weeks working as a data science in...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442</td>\n",
       "      <td>Need resources to improve my analytical skills</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5325</td>\n",
       "      <td>[P] Emotional Context bot test.</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3926</td>\n",
       "      <td>Should 0fr be explicitly forbidden as a value ...</td>\n",
       "      <td>css</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>Customer segmentation and category association...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3067</td>\n",
       "      <td>CSS is not applied on HTML error page in a sub...</td>\n",
       "      <td>html</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3311</td>\n",
       "      <td>Is there a way to add code to several classes ...</td>\n",
       "      <td>html</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3842</td>\n",
       "      <td>Keeping \"tooltip\" div on screen.</td>\n",
       "      <td>css</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>How do you host your models?</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3855</td>\n",
       "      <td>Responsive Grid Magazine Layout in Just 20 Lin...</td>\n",
       "      <td>css</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6305</td>\n",
       "      <td>How MLB does pitch classification in the ballpark</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1499</td>\n",
       "      <td>New to Kaggle -can you add to competition data...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3303</td>\n",
       "      <td>Python in html</td>\n",
       "      <td>html</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2230</td>\n",
       "      <td>[D] Finding time for personal development work...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4194</td>\n",
       "      <td>How to get these rotating 3d gifs?</td>\n",
       "      <td>css</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5431</td>\n",
       "      <td>[D] [R] Theory behind stochastic gradient descent</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2332</td>\n",
       "      <td>What was your biggest disillusionment/disappoi...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4919</td>\n",
       "      <td>[P] NNSplit: fast and robust sentence splitting</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2644</td>\n",
       "      <td>How should I prepare for a Data Scientist inte...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>574</td>\n",
       "      <td>Issues with scipy.integrate and normal distrib...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4829</td>\n",
       "      <td>[R] SLIDE algorithm for training deep neural n...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6086</td>\n",
       "      <td>[D] Finding time for personal development work...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2275</td>\n",
       "      <td>Python fit curve “Envelope” model</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4951</td>\n",
       "      <td>[D] I think i found a blog that is being writt...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title        subreddit  \\\n",
       "2667  How many years of data is sufficient for an an...      datascience   \n",
       "2450                       Association of store's names      datascience   \n",
       "6503                Do you leave your EDA in notebooks?      datascience   \n",
       "6526                   big data no budget best practice      datascience   \n",
       "4342  Is it possible to code a wordpress theme (veni...              css   \n",
       "2490   This made me laugh harder than it should lol....      datascience   \n",
       "489   It's been 2 weeks working as a data science in...      datascience   \n",
       "442      Need resources to improve my analytical skills      datascience   \n",
       "5325                    [P] Emotional Context bot test.  machinelearning   \n",
       "3926  Should 0fr be explicitly forbidden as a value ...              css   \n",
       "165   Customer segmentation and category association...      datascience   \n",
       "3067  CSS is not applied on HTML error page in a sub...             html   \n",
       "3311  Is there a way to add code to several classes ...             html   \n",
       "3842                   Keeping \"tooltip\" div on screen.              css   \n",
       "103                        How do you host your models?      datascience   \n",
       "3855  Responsive Grid Magazine Layout in Just 20 Lin...              css   \n",
       "6305  How MLB does pitch classification in the ballpark      datascience   \n",
       "1499  New to Kaggle -can you add to competition data...      datascience   \n",
       "3303                                     Python in html             html   \n",
       "2230  [D] Finding time for personal development work...      datascience   \n",
       "4194                 How to get these rotating 3d gifs?              css   \n",
       "5431  [D] [R] Theory behind stochastic gradient descent  machinelearning   \n",
       "2332  What was your biggest disillusionment/disappoi...      datascience   \n",
       "4919    [P] NNSplit: fast and robust sentence splitting  machinelearning   \n",
       "2644  How should I prepare for a Data Scientist inte...      datascience   \n",
       "574   Issues with scipy.integrate and normal distrib...      datascience   \n",
       "4829  [R] SLIDE algorithm for training deep neural n...  machinelearning   \n",
       "6086  [D] Finding time for personal development work...      datascience   \n",
       "2275                  Python fit curve “Envelope” model      datascience   \n",
       "4951  [D] I think i found a blog that is being writt...  machinelearning   \n",
       "\n",
       "            date  sub_code  \n",
       "2667  2020-03-10         0  \n",
       "2450  2020-03-10         0  \n",
       "6503  2020-03-10         0  \n",
       "6526  2020-03-10         0  \n",
       "4342  2020-03-10         2  \n",
       "2490  2020-03-10         0  \n",
       "489   2020-03-10         0  \n",
       "442   2020-03-10         0  \n",
       "5325  2020-03-10         3  \n",
       "3926  2020-03-10         2  \n",
       "165   2020-03-10         0  \n",
       "3067  2020-03-10         1  \n",
       "3311  2020-03-10         1  \n",
       "3842  2020-03-10         2  \n",
       "103   2020-03-10         0  \n",
       "3855  2020-03-10         2  \n",
       "6305  2020-03-10         0  \n",
       "1499  2020-03-10         0  \n",
       "3303  2020-03-10         1  \n",
       "2230  2020-03-10         0  \n",
       "4194  2020-03-10         2  \n",
       "5431  2020-03-10         3  \n",
       "2332  2020-03-10         0  \n",
       "4919  2020-03-10         3  \n",
       "2644  2020-03-10         0  \n",
       "574   2020-03-10         0  \n",
       "4829  2020-03-10         3  \n",
       "6086  2020-03-10         0  \n",
       "2275  2020-03-10         0  \n",
       "4951  2020-03-10         3  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title']\n",
    "y = df['sub_code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using CountVectorizer here to get a word count of all the words in the subreddits in order to visualize them.  \n",
    "*Note*  \n",
    "This should be available after fitting model, but I could not figure completely out the convoluted method to get to the items through the pipeline, grid, best_estimator, steps, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stops = ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stops = my_stops.union(trimmed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stops = my_stops.union(['using', 'help', 'new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words=my_stops, min_df=5)\n",
    "\n",
    "features = pd.DataFrame(cv.fit_transform(df['title']).toarray(),\n",
    "                        columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_common = features.sum().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Combined Most Common Words')\n",
    "base_common.plot.barh();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=len(trimmed_list), figsize=(15,6*len(trimmed_list)))\n",
    "\n",
    "for subplot_idx, sub in enumerate(trimmed_list):\n",
    "    topic_features = features.loc[df['subreddit'] == sub, :]\n",
    "    topic_features_to_plot = topic_features[base_common.index].sum()\n",
    "    \n",
    "    topic_features_to_plot.plot(kind='barh', ax=ax[subplot_idx])\n",
    "    max_occurence = features.sum().max()\n",
    "    ax[subplot_idx].set_xlim(0,max_occurence)\n",
    "    ax[subplot_idx].set_title(topic.upper(), fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo for this section\n",
    "\n",
    "1. make each of these functions only take two "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15,6))\n",
    "sci[base_common.index].sum().plot.barh(ax=ax1, title='Science', color='navy')\n",
    "ax1.set_xlim(0,2800)\n",
    "ax2.set_xlim(0,2800)\n",
    "tech[base_common.index].sum().plot.barh(ax=ax2, title='Technology', color='orange');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "\n",
    "\n",
    "groups = features.groupby(df['subreddit']).sum()[base_common.index].T.head(20)\n",
    "plt.title('20 Most Common Words', fontsize=20)\n",
    "\n",
    "groups.plot.bar(\n",
    "                ax=ax,\n",
    "                width=.8,\n",
    "                # set style for colors instead of have to choose individually\n",
    "                color=['gray','navy','orange','purple','red'],\n",
    "                fontsize=15,\n",
    "                );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Clouds!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_cloud(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 6*len(trimmed_list)))\n",
    "for i, sub in enumerate(trimmed_list):\n",
    "    ax = fig.add_subplot(len(trimmed_list),1,i+1)\n",
    "    cloud = make_cloud(X=df[df['subreddit'] == sub]['title'])\n",
    "    \n",
    "\n",
    "    ax.set_title(topic.upper(), fontdict={'fontsize': 24})\n",
    "    ax.imshow(cloud)\n",
    "    ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline([('count_vec', TfidfVectorizer()), ('lr', LogisticRegression())])\n",
    "\n",
    "pipe_params = {\n",
    "                'count_vec__max_features': [5000],\n",
    "                'count_vec__max_df': [.3,.4,.5],\n",
    "                'count_vec__ngram_range': [(1,2)],\n",
    "                'count_vec__stop_words': [my_stops],\n",
    "                'count_vec__min_df': [4,5,6],\n",
    "                'lr__penalty': ['l1'],\n",
    "                'lr__C': [1]\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_grid = GridSearchCV(lr_pipe, param_grid=pipe_params, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "lr_grid.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(lr_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do for this section\n",
    "\n",
    "1. Confusion Matrix for all selected Topics\n",
    "2. Make a function that will compare all topics in 1x1 fasion, find combinatorics or whatever Python library\n",
    "3. Output each of the comparisons if a list of more than 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions = lr_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cm = confusion_matrix(y_test, lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_confusion_df = pd.DataFrame(lr_cm, columns=topics, index=topics)\n",
    "\n",
    "lr_confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = lr_cm.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_spec = tn / (tn + fp)\n",
    "lr_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity/Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_sens = tp / (tp +fn)\n",
    "lr_sens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_auc = roc_auc_score(y_test, lr_predictions)\n",
    "lr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = lr_grid.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not multiclass\n",
    "lr_fpr, lr_tpr, lr_thresholds = roc_curve(y_test, lr_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(lr_fpr, lr_tpr, label=f'ROC curve (area = {lr_auc})', color='r', marker='D')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)', size=16)\n",
    "plt.ylabel('True Positive Rate (Sensitivity)', size=16)\n",
    "plt.title('ROC Curve Logistic Regression', size=20)\n",
    "plt.legend(fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create figure.\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "# Create histogram of observations.\n",
    "plt.hist(lr_probs, bins=25, color='b')\n",
    "\n",
    "# Label axes.\n",
    "plt.title('Distribution of P(Outcome = 1)', fontsize=22)\n",
    "plt.ylabel('Frequency', fontsize=18)\n",
    "plt.xlabel('Predicted Probability that Outcome = 1', fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure.\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "# Create two histograms of observations.\n",
    "hst0 = plt.hist(lr_probs[y_test == 0],\n",
    "         bins=25,\n",
    "         color='b',\n",
    "         alpha = 0.6,\n",
    "         label='Technology',)\n",
    "\n",
    "hst1 = plt.hist(lr_probs[y_test == 1],\n",
    "         bins=25,\n",
    "         color='orange',\n",
    "         alpha = 0.6,\n",
    "         label='Science')\n",
    "\n",
    "# Add vertical line at P(Outcome = 1) = 0.5.\n",
    "plt.vlines(x=0.5,\n",
    "           ymin = 0,\n",
    "           ymax = max(hst1[0].max(), hst0[0].max()), # Max of the two highest respective hist values\n",
    "           color='r',\n",
    "           linestyle = '--')\n",
    "\n",
    "# Label axes.\n",
    "plt.title('Distribution of P(Science)', fontsize=22)\n",
    "plt.ylabel('Frequency', fontsize=18)\n",
    "plt.xlabel('Predicted Probability', fontsize=18)\n",
    "\n",
    "# Create legend.\n",
    "plt.legend(fontsize=20);\n",
    "\n",
    "# Thanks to Matt Brems for the colorful graphs! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_feats = lr_grid.best_estimator_.named_steps['tfidf'].get_feature_names()\n",
    "\n",
    "lr_catcher = lr_grid.best_estimator_.named_steps['lr']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.title('Feature Importance (Coefficients)', fontsize=20)\n",
    "plt.ylabel('Features', fontsize=18)\n",
    "plt.xlabel('(Abs) Coefficients', fontsize=18)\n",
    "\n",
    "coef_df = pd.DataFrame(lr_catcher.coef_, columns=lr_feats).T\n",
    "coef_df['abs_coef'] = coef_df[0].abs()\n",
    "coef_df.sort_values('abs_coef', ascending=False)[0].head(15).plot(kind='barh');\n",
    "\n",
    "# coef_kill = coef_df.sort_values('abs_coef', ascending=False)[0].head(500).index\n",
    "\n",
    "# coef_kill\n",
    "\n",
    "\n",
    "# my_stops.extend(coef_kill)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
