{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Workflow\n",
    "## Find the Best Model\n",
    "\n",
    "This notebook shows how to use some of the functions located in `reddit_functions` to compare the performance of different models on the data.\n",
    "\n",
    "A second workflow is included to take the parameters of the best model and create a new model and fit it on the entire dataset and see the improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for jupyter to find my modules and packages\n",
    "# import sys\n",
    "# sys.path\n",
    "# sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import grid_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.reddit_functions import Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subreddit_list = ['css', 'html', 'javascript', 'php', 'perl', 'java', 'datascience', 'machinelearning', 'etl', 'python', 'dataengineering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_list = ['datascience','machinelearning','dataengineering','python','aws','sql']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to SQLite DB successful\n"
     ]
    }
   ],
   "source": [
    "df = dataloader.data_selector(subreddit_list, 'sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datascience', 'machinelearning', 'dataengineering', 'python', 'aws', 'sql']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid of list items with no data retrieved\n",
    "subreddit_list = [sub for sub in subreddit_list if sub in df.subreddit.unique()]\n",
    "subreddit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddits and codes added: {'aws': 0, 'sql': 1, 'datascience': 2, 'machinelearning': 3, 'python': 4, 'dataengineering': 5}\n"
     ]
    }
   ],
   "source": [
    "df = dataloader.subreddit_encoder(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>date</th>\n",
       "      <th>sub_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8893</th>\n",
       "      <td>A quick speech synthesis project—is Tacotron 2...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7629</th>\n",
       "      <td>Finding duplicates across multiple columns. Is...</td>\n",
       "      <td>sql</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>Newbie Question - Which is easier to learn Pyt...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>An outsider's opinion of data quality. (My bac...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8224</th>\n",
       "      <td>Looking for experienced team buddies for Faceb...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5449</th>\n",
       "      <td>Apache Spark for dotnet developers</td>\n",
       "      <td>dataengineering</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10192</th>\n",
       "      <td>Python package to detect emotion using tone of...</td>\n",
       "      <td>python</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8240</th>\n",
       "      <td>[UK] Bachelors degree in engineering, what els...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017</th>\n",
       "      <td>Boids - organic motion from 3 simple rules</td>\n",
       "      <td>python</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9312</th>\n",
       "      <td>[R] KaoKore: A Pre-modern Japanese Art Facial ...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title        subreddit  \\\n",
       "8893   A quick speech synthesis project—is Tacotron 2...  machinelearning   \n",
       "7629   Finding duplicates across multiple columns. Is...              sql   \n",
       "2835   Newbie Question - Which is easier to learn Pyt...      datascience   \n",
       "2518   An outsider's opinion of data quality. (My bac...      datascience   \n",
       "8224   Looking for experienced team buddies for Faceb...      datascience   \n",
       "5449                  Apache Spark for dotnet developers  dataengineering   \n",
       "10192  Python package to detect emotion using tone of...           python   \n",
       "8240   [UK] Bachelors degree in engineering, what els...      datascience   \n",
       "4017          Boids - organic motion from 3 simple rules           python   \n",
       "9312   [R] KaoKore: A Pre-modern Japanese Art Facial ...  machinelearning   \n",
       "\n",
       "             date  sub_code  \n",
       "8893   2020-04-02         3  \n",
       "7629   2020-04-02         1  \n",
       "2835   2020-03-29         2  \n",
       "2518   2020-03-29         2  \n",
       "8224   2020-04-02         2  \n",
       "5449   2020-03-29         5  \n",
       "10192  2020-04-02         4  \n",
       "8240   2020-04-02         2  \n",
       "4017   2020-03-29         4  \n",
       "9312   2020-04-02         3  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title']\n",
    "y = df['sub_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_words = set(['using', 'help', 'new', 'data', 'science', 'machine', 'learning', 'use', 'need'])\n",
    "\n",
    "custom_stop_words = ENGLISH_STOP_WORDS.union(subreddit_list, useless_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "redfuncs = Reddit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessors = grid_models.preprocessors\n",
    "estimators = grid_models.estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Subset of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esty = {'logreg': estimators['logreg']}\n",
    "\n",
    "# compare_df = redfun.compare_models(X_train, X_test, y_train, y_test, estimators=esty, cv=3, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed:   13.2s finished\n",
      "/Users/chris/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    1.4s finished\n",
      "/Users/chris/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 324 out of 324 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "/Users/chris/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   19.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "/Users/chris/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:   19.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    1.9s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   56.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  5.5min\n",
      "/Users/chris/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 486 out of 486 | elapsed: 15.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "/Users/chris/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:  2.2min finished\n"
     ]
    }
   ],
   "source": [
    "compare_df = redfuncs.compare_models(X_train, X_test, y_train, y_test, cv=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessor</th>\n",
       "      <th>Estimator</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Best Train Score</th>\n",
       "      <th>Best Test Score</th>\n",
       "      <th>Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>svc</td>\n",
       "      <td>{'svc__C': 3, 'svc__degree': 1, 'svc__gamma': ...</td>\n",
       "      <td>0.993373</td>\n",
       "      <td>0.894003</td>\n",
       "      <td>10.003301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>count_vec</td>\n",
       "      <td>svc</td>\n",
       "      <td>{'count_vec__max_df': 0.3, 'count_vec__max_fea...</td>\n",
       "      <td>0.980467</td>\n",
       "      <td>0.862622</td>\n",
       "      <td>12.019304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count_vec</td>\n",
       "      <td>logreg</td>\n",
       "      <td>{'count_vec__max_df': 0.3, 'count_vec__max_fea...</td>\n",
       "      <td>0.971050</td>\n",
       "      <td>0.848675</td>\n",
       "      <td>12.602323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>logreg</td>\n",
       "      <td>{'logreg__C': 3, 'logreg__penalty': 'l2', 'tfi...</td>\n",
       "      <td>0.955121</td>\n",
       "      <td>0.841702</td>\n",
       "      <td>11.874925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>randomforest</td>\n",
       "      <td>{'randomforest__max_depth': 200, 'randomforest...</td>\n",
       "      <td>0.954191</td>\n",
       "      <td>0.838215</td>\n",
       "      <td>12.154437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>count_vec</td>\n",
       "      <td>randomforest</td>\n",
       "      <td>{'count_vec__max_df': 0.3, 'count_vec__max_fea...</td>\n",
       "      <td>0.935473</td>\n",
       "      <td>0.822176</td>\n",
       "      <td>12.111192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>multinomialnb</td>\n",
       "      <td>{'multinomialnb__alpha': 1, 'multinomialnb__fi...</td>\n",
       "      <td>0.894663</td>\n",
       "      <td>0.795328</td>\n",
       "      <td>11.103132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>count_vec</td>\n",
       "      <td>multinomialnb</td>\n",
       "      <td>{'count_vec__max_df': 0.3, 'count_vec__max_fea...</td>\n",
       "      <td>0.853738</td>\n",
       "      <td>0.776499</td>\n",
       "      <td>9.047113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>count_vec</td>\n",
       "      <td>knearest</td>\n",
       "      <td>{'count_vec__max_df': 0.3, 'count_vec__max_fea...</td>\n",
       "      <td>0.806999</td>\n",
       "      <td>0.625523</td>\n",
       "      <td>22.487777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>knearest</td>\n",
       "      <td>{'knearest__metric': 'manhattan', 'knearest__n...</td>\n",
       "      <td>0.787699</td>\n",
       "      <td>0.313808</td>\n",
       "      <td>60.161497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Preprocessor      Estimator  \\\n",
       "9        tfidf            svc   \n",
       "8    count_vec            svc   \n",
       "0    count_vec         logreg   \n",
       "1        tfidf         logreg   \n",
       "3        tfidf   randomforest   \n",
       "2    count_vec   randomforest   \n",
       "7        tfidf  multinomialnb   \n",
       "6    count_vec  multinomialnb   \n",
       "4    count_vec       knearest   \n",
       "5        tfidf       knearest   \n",
       "\n",
       "                                         Best Params  Best Train Score  \\\n",
       "9  {'svc__C': 3, 'svc__degree': 1, 'svc__gamma': ...          0.993373   \n",
       "8  {'count_vec__max_df': 0.3, 'count_vec__max_fea...          0.980467   \n",
       "0  {'count_vec__max_df': 0.3, 'count_vec__max_fea...          0.971050   \n",
       "1  {'logreg__C': 3, 'logreg__penalty': 'l2', 'tfi...          0.955121   \n",
       "3  {'randomforest__max_depth': 200, 'randomforest...          0.954191   \n",
       "2  {'count_vec__max_df': 0.3, 'count_vec__max_fea...          0.935473   \n",
       "7  {'multinomialnb__alpha': 1, 'multinomialnb__fi...          0.894663   \n",
       "6  {'count_vec__max_df': 0.3, 'count_vec__max_fea...          0.853738   \n",
       "4  {'count_vec__max_df': 0.3, 'count_vec__max_fea...          0.806999   \n",
       "5  {'knearest__metric': 'manhattan', 'knearest__n...          0.787699   \n",
       "\n",
       "   Best Test Score   Variance  \n",
       "9         0.894003  10.003301  \n",
       "8         0.862622  12.019304  \n",
       "0         0.848675  12.602323  \n",
       "1         0.841702  11.874925  \n",
       "3         0.838215  12.154437  \n",
       "2         0.822176  12.111192  \n",
       "7         0.795328  11.103132  \n",
       "6         0.776499   9.047113  \n",
       "4         0.625523  22.487777  \n",
       "5         0.313808  60.161497  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_df.sort_values(by='Best Test Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df.to_csv('compare_df_04022020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 3,\n",
      " 'svc__degree': 1,\n",
      " 'svc__gamma': 'scale',\n",
      " 'svc__kernel': 'rbf',\n",
      " 'svc__probability': True,\n",
      " 'tfidf__max_features': 5000,\n",
      " 'tfidf__ngram_range': (1, 1),\n",
      " 'tfidf__stop_words': 'english',\n",
      " 'tfidf__strip_accents': None}\n",
      "{'count_vec__max_df': 0.3,\n",
      " 'count_vec__max_features': 5000,\n",
      " 'count_vec__min_df': 4,\n",
      " 'count_vec__ngram_range': (1, 2),\n",
      " 'count_vec__stop_words': 'english',\n",
      " 'svc__C': 3,\n",
      " 'svc__degree': 1,\n",
      " 'svc__gamma': 'scale',\n",
      " 'svc__kernel': 'rbf',\n",
      " 'svc__probability': True}\n",
      "{'count_vec__max_df': 0.3,\n",
      " 'count_vec__max_features': 5000,\n",
      " 'count_vec__min_df': 4,\n",
      " 'count_vec__ngram_range': (1, 2),\n",
      " 'count_vec__stop_words': 'english',\n",
      " 'logreg__C': 3,\n",
      " 'logreg__penalty': 'l2'}\n",
      "{'logreg__C': 3,\n",
      " 'logreg__penalty': 'l2',\n",
      " 'tfidf__max_features': 5000,\n",
      " 'tfidf__ngram_range': (1, 1),\n",
      " 'tfidf__stop_words': 'english',\n",
      " 'tfidf__strip_accents': None}\n",
      "{'randomforest__max_depth': 200,\n",
      " 'randomforest__min_samples_leaf': 1,\n",
      " 'randomforest__min_samples_split': 0.001,\n",
      " 'randomforest__n_estimators': 300,\n",
      " 'tfidf__max_features': 5000,\n",
      " 'tfidf__ngram_range': (1, 1),\n",
      " 'tfidf__stop_words': 'english',\n",
      " 'tfidf__strip_accents': None}\n",
      "{'count_vec__max_df': 0.3,\n",
      " 'count_vec__max_features': 5000,\n",
      " 'count_vec__min_df': 4,\n",
      " 'count_vec__ngram_range': (1, 2),\n",
      " 'count_vec__stop_words': 'english',\n",
      " 'randomforest__max_depth': 200,\n",
      " 'randomforest__min_samples_leaf': 1,\n",
      " 'randomforest__min_samples_split': 0.001,\n",
      " 'randomforest__n_estimators': 300}\n",
      "{'multinomialnb__alpha': 1,\n",
      " 'multinomialnb__fit_prior': False,\n",
      " 'tfidf__max_features': 5000,\n",
      " 'tfidf__ngram_range': (1, 1),\n",
      " 'tfidf__stop_words': 'english',\n",
      " 'tfidf__strip_accents': None}\n",
      "{'count_vec__max_df': 0.3,\n",
      " 'count_vec__max_features': 5000,\n",
      " 'count_vec__min_df': 4,\n",
      " 'count_vec__ngram_range': (1, 2),\n",
      " 'count_vec__stop_words': 'english',\n",
      " 'multinomialnb__alpha': 1,\n",
      " 'multinomialnb__fit_prior': False}\n",
      "{'count_vec__max_df': 0.3,\n",
      " 'count_vec__max_features': 5000,\n",
      " 'count_vec__min_df': 6,\n",
      " 'count_vec__ngram_range': (1, 2),\n",
      " 'count_vec__stop_words': 'english',\n",
      " 'knearest__metric': 'manhattan',\n",
      " 'knearest__n_neighbors': 5}\n",
      "{'knearest__metric': 'manhattan',\n",
      " 'knearest__n_neighbors': 3,\n",
      " 'tfidf__max_features': 5000,\n",
      " 'tfidf__ngram_range': (1, 1),\n",
      " 'tfidf__stop_words': 'english',\n",
      " 'tfidf__strip_accents': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pprint(params) for params in compare_df.sort_values(by='Best Test Score', ascending=False)['Best Params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Preprocessor': 'tfidf',\n",
       " 'Estimator': 'svc',\n",
       " 'Best Params': {'svc__C': 3,\n",
       "  'svc__degree': 1,\n",
       "  'svc__gamma': 'scale',\n",
       "  'svc__kernel': 'rbf',\n",
       "  'svc__probability': True,\n",
       "  'tfidf__max_features': 5000,\n",
       "  'tfidf__ngram_range': (1, 1),\n",
       "  'tfidf__stop_words': 'english',\n",
       "  'tfidf__strip_accents': None},\n",
       " 'Best Train Score': 0.9933728636205092,\n",
       " 'Best Test Score': 0.8940027894002789,\n",
       " 'Variance': 10.003300659740184}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = compare_df.sort_values(by='Best Test Score', ascending=False).iloc[0, :].to_dict()\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a new model with the best params from the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9566688123628602"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipe = Pipeline([\n",
    "    (best_model['Preprocessor'], preprocessors[best_model['Preprocessor']]['processor']),\n",
    "    (best_model['Estimator'], estimators[best_model['Estimator']]['estimator'])\n",
    "])\n",
    "best_pipe.set_params(**best_model['Best Params'])\n",
    "# fit on entire dataset\n",
    "# best_pipe.fit(X, y)\n",
    "crossval = cross_val_score(best_pipe, X=X, y=y, cv=5)\n",
    "crossval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9911936524544425"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipe_score = best_pipe.score(X, y)\n",
    "best_pipe_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.173773\n",
       "3    0.173250\n",
       "5    0.170285\n",
       "1    0.167669\n",
       "4    0.161479\n",
       "2    0.153544\n",
       "Name: sub_code, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8174208736594298"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how much improvement over baseline\n",
    "best_pipe_score - y.value_counts(normalize=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6773861210736893"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how much difference from the best worst model to the best best model\n",
    "best_pipe_score - min(compare_df['Best Test Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09719086305416358"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how much improvement from retraining on entire dataset\n",
    "best_pipe_score - best_model['Best Test Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
