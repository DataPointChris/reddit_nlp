{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "## TODO\n",
    "\n",
    "1. make a for loop to go over each model, to avoid typing out everything multiple times\n",
    "2. Make each model have the scoring and confusion matrix, and the validation plot\n",
    "3. Learn about the validation plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is gridsearch for each model\n",
    "\n",
    "https://stackabuse.com/grid-search-optimization-algorithm-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import databases\n",
    "from util import dataloader\n",
    "from util import grid_models\n",
    "from util.reddit_functions import Labeler\n",
    "from util.reddit_functions import plot_confusion_matrix\n",
    "from util.grid_models import custom_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subreddit_list = ['css', 'html', 'javascript', 'php', 'perl', 'java', 'datascience', 'machinelearning', 'etl', 'python', 'dataengineering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_list = ['datascience','machinelearning','dataengineering','python','aws']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to SQLite DB successful\n"
     ]
    }
   ],
   "source": [
    "df = dataloader.data_selector(subreddit_list, 'sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26204</th>\n",
       "      <td>[D] What is the current approach for image cla...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>2020-04-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19073</th>\n",
       "      <td>“Oh, you’re a data… something?”: The Misunders...</td>\n",
       "      <td>dataengineering</td>\n",
       "      <td>2020-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48467</th>\n",
       "      <td>Can't run mysql with an EBS volume in EKS kube...</td>\n",
       "      <td>aws</td>\n",
       "      <td>2020-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12289</th>\n",
       "      <td>[P] Follow-up work on the baikal library</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>2020-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43031</th>\n",
       "      <td>AWS is deprecating its pricing calculator, so ...</td>\n",
       "      <td>aws</td>\n",
       "      <td>2020-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>[Discussion] Convolutional Variational Autoenc...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>2020-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>[D] Socially Beneficial Uses of DeepFakes</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>2020-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27155</th>\n",
       "      <td>covid report for nation state and county from ...</td>\n",
       "      <td>python</td>\n",
       "      <td>2020-04-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29366</th>\n",
       "      <td>Question about creating an EC2 instance that c...</td>\n",
       "      <td>aws</td>\n",
       "      <td>2020-04-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6382</th>\n",
       "      <td>How to learn Data Science???</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-04-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title        subreddit  \\\n",
       "26204  [D] What is the current approach for image cla...  machinelearning   \n",
       "19073  “Oh, you’re a data… something?”: The Misunders...  dataengineering   \n",
       "48467  Can't run mysql with an EBS volume in EKS kube...              aws   \n",
       "12289           [P] Follow-up work on the baikal library  machinelearning   \n",
       "43031  AWS is deprecating its pricing calculator, so ...              aws   \n",
       "2234   [Discussion] Convolutional Variational Autoenc...  machinelearning   \n",
       "7329           [D] Socially Beneficial Uses of DeepFakes  machinelearning   \n",
       "27155  covid report for nation state and county from ...           python   \n",
       "29366  Question about creating an EC2 instance that c...              aws   \n",
       "6382                        How to learn Data Science???      datascience   \n",
       "\n",
       "             date  \n",
       "26204  2020-04-21  \n",
       "19073  2020-04-14  \n",
       "48467  2020-04-27  \n",
       "12289  2020-04-10  \n",
       "43031  2020-04-25  \n",
       "2234   2020-03-29  \n",
       "7329   2020-04-02  \n",
       "27155  2020-04-21  \n",
       "29366  2020-04-22  \n",
       "6382   2020-04-02  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title']\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler = Labeler()\n",
    "labeler.fit(y)\n",
    "y = labeler.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=custom_stop_words)\n",
    "\n",
    "tfidf_params = \n",
    "    \"tfidf__ngram_range\": [(1, 2)],\n",
    "#     \"tfidf__max_features\": [1000, 3000, 5000],\n",
    "    \"tfidf__max_df\": [.75, .8, .85, .9],\n",
    "    \"tfidf__use_idf\": [True],\n",
    "    \"tfidf__norm\": [\"l1\", \"l2\"],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_model(preprocessor, classifier, pipeline, pipe_params, cv=3, verbose=1):\n",
    "    '''\n",
    "    Takes a dictionary with params and outputs a fitted model\n",
    "    '''\n",
    "    pipe = Pipeline(\n",
    "    [('preprocessor', pre),\n",
    "     ('classifier', clf)])\n",
    "    \n",
    "    model = GridSearchCV(pipe, param_grid=pipe_params, cv=cv, verbose=verbose, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    print(f'Train Score: {model.score(X_train, y_train)}')\n",
    "    print(f'Test Score: {model.score(X_test, y_test)}')\n",
    "    print(f'AUC Score: {roc_auc_score(y_test, y_proba)}')\n",
    "    print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = {\n",
    "    'clf': MLPClassifier(),\n",
    "    'clf_params': {\n",
    "        \"mlp__hidden_layer_sizes\": [50, 100, 200]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = {\n",
    "    'clf': XGBClassifier(),\n",
    "    'clf_params': {\n",
    "        \"xgb__hidden_layer_sizes\": [10, 25, 50],\n",
    "        \"xgb__n_estimators\": [50, 100, 200],\n",
    "        \"xgb__max_depth\": [5, 10, 20]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "onevrest = {\n",
    "    'clf': OneVsRestClassifier(RandomForestClassifier()),\n",
    "    'clf_params': {\n",
    "        \"tfidf__ngram_range\": [(1, 2)],\n",
    "        \"tfidf__max_features\": [4500, 5000, 5500],\n",
    "        \"tfidf__max_df\": [.75, .8, .85],\n",
    "        \"tfidf__use_idf\": [True],\n",
    "        \"tfidf__norm\": [\"l2\"],\n",
    "        \"onevrest__estimator__n_estimators\": [200, 300]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.learning_curve import validation_curve\n",
    "degree = np.arange(0, 21)\n",
    "train_score, val_score = validation_curve(PolynomialRegression(), X, y,\n",
    "'polynomialfeatures__degree', degree, cv=7)\n",
    "plt.plot(degree, np.median(train_score, 1), color='blue', label='training score') plt.plot(degree, np.median(val_score, 1), color='red', label='validation score') plt.legend(loc='best')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('degree') plt.ylabel('score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcm = multilabel_confusion_matrix(y_test, y_pred)\n",
    "mtn = mcm[:, 0, 0]\n",
    "mtp = mcm[:, 1, 1]\n",
    "mfn = mcm[:, 1, 0]\n",
    "mfp = mcm[:, 0, 1]\n",
    "print(mcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TODO:</h1>\n",
    "\n",
    "1. Make it have the roc for each sub, have to get into the original df where subname equals indexes?\n",
    "2. Plot confusion matrix\n",
    "3. Make a notebook to test the confusion matrixes one by one with each individual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df = pd.DataFrame(y_prob, columns=subreddit_list)\n",
    "prob_df.round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
