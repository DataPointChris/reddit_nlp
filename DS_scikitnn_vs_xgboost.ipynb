{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Workflow\n",
    "\n",
    "This is a notebook for testing all of the functions to go through an entire data science workflow of running NLP on chosen subreddits.\n",
    "\n",
    "**Future**\n",
    "- DF functions should be removed from workflow and imported using a class.\n",
    "- Multiple example DS outcomes would be nice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is gridsearch for each model\n",
    "\n",
    "https://stackabuse.com/grid-search-optimization-algorithm-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/chris/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/chris/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/chris/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/chris/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/chris/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import databases\n",
    "from helpers import dataloader\n",
    "from helpers import grid_models\n",
    "from helpers.reddit_functions import Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subreddit_list = ['css', 'html', 'javascript', 'php', 'perl', 'java', 'datascience', 'machinelearning', 'etl', 'python', 'dataengineering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_list = ['datascience','machinelearning','dataengineering','python','aws']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to SQLite DB successful\n"
     ]
    }
   ],
   "source": [
    "df = dataloader.data_selector(subreddit_list, 'sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datascience', 'machinelearning', 'dataengineering', 'python', 'aws']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid of list items with no data retrieved\n",
    "subreddit_list = [sub for sub in subreddit_list if sub in df.subreddit.unique()]\n",
    "subreddit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddits and codes added: {'aws': 0, 'datascience': 1, 'machinelearning': 2, 'python': 3, 'dataengineering': 4}\n"
     ]
    }
   ],
   "source": [
    "df = dataloader.subreddit_encoder(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>date</th>\n",
       "      <th>sub_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>[D][R] Persistent Memory Cloud Compute-- Early...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>Recommended CI/CD for a site using CloudFront,...</td>\n",
       "      <td>aws</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>Codecademy is giving its pro subscription for ...</td>\n",
       "      <td>python</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>What do you use for data analysis?</td>\n",
       "      <td>dataengineering</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6507</th>\n",
       "      <td>Data Science Project Suggestions</td>\n",
       "      <td>datascience</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>A safe Python twitter bot to post tweet using ...</td>\n",
       "      <td>python</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8842</th>\n",
       "      <td>A Data Engineer's Naive Foray Into Data Science</td>\n",
       "      <td>dataengineering</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7796</th>\n",
       "      <td>Why can't I install anaconda ?</td>\n",
       "      <td>python</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>[R] Kaggle Competition on COVID19 Dataset by A...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7036</th>\n",
       "      <td>[D] I need some help with deploying an LSTM mo...</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title        subreddit  \\\n",
       "7086  [D][R] Persistent Memory Cloud Compute-- Early...  machinelearning   \n",
       "5338  Recommended CI/CD for a site using CloudFront,...              aws   \n",
       "3257  Codecademy is giving its pro subscription for ...           python   \n",
       "8766                 What do you use for data analysis?  dataengineering   \n",
       "6507                   Data Science Project Suggestions      datascience   \n",
       "3190  A safe Python twitter bot to post tweet using ...           python   \n",
       "8842    A Data Engineer's Naive Foray Into Data Science  dataengineering   \n",
       "7796                     Why can't I install anaconda ?           python   \n",
       "2136  [R] Kaggle Competition on COVID19 Dataset by A...  machinelearning   \n",
       "7036  [D] I need some help with deploying an LSTM mo...  machinelearning   \n",
       "\n",
       "            date  sub_code  \n",
       "7086  2020-04-02         2  \n",
       "5338  2020-04-02         0  \n",
       "3257  2020-03-29         3  \n",
       "8766  2020-04-02         4  \n",
       "6507  2020-04-02         1  \n",
       "3190  2020-03-29         3  \n",
       "8842  2020-04-02         4  \n",
       "7796  2020-04-02         3  \n",
       "2136  2020-03-29         2  \n",
       "7036  2020-04-02         2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title']\n",
    "y = df['sub_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_words = set(['using', 'help', 'new', 'data', 'science', 'machine', 'learning', 'use', 'need'])\n",
    "\n",
    "custom_stop_words = ENGLISH_STOP_WORDS.union(subreddit_list, useless_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "redfuncs = Reddit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=custom_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.1min\n",
      "/Users/chris/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed: 61.4min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-9ece57cfe968>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmlp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_pipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlp_pipe_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmlp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Train Score: {mlp_model.score(X_train, y_train)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Score: {mlp_model.score(X_test, y_test)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "\n",
    "mlp_pipe = Pipeline(\n",
    "    [('tfidf', tfidf),\n",
    "     ('mlp', mlp)])\n",
    "\n",
    "mlp_pipe_params = {\n",
    "    \"tfidf__ngram_range\": [(1, 2),(2, 2),(2,3)],\n",
    "#     \"tfidf__max_features\": [1000, 3000, 5000],\n",
    "    \"tfidf__max_df\": [.75, .8, .85, .9],\n",
    "    \"tfidf__use_idf\": [True],\n",
    "    \"tfidf__norm\": [\"l1\", \"l2\"],\n",
    "#     \"mlp__hidden_layer_sizes\": [50, 100, 200]\n",
    "}\n",
    "\n",
    "\n",
    "mlp_model = GridSearchCV(mlp_pipe, param_grid=mlp_pipe_params, cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "mlp_model.fit(X_train, y_train)\n",
    "print(f'Train Score: {mlp_model.score(X_train, y_train)}')\n",
    "print(f'Test Score: {mlp_model.score(X_test, y_test)}')\n",
    "mlp_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 864 candidates, totalling 1728 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1434 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1728 out of 1728 | elapsed: 17.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.8043022768543092\n",
      "Test Score: 0.6941767909509845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.5, max_features=3000,\n",
       "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=frozenset({'a', 'about', 'above',\n",
       "                                                       'across', 'after',\n",
       "                                                       'afterward...\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0,\n",
       "                               hidden_layer_sizes=50, learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=5,\n",
       "                               min_child_weight=1, missing=None,\n",
       "                               n_estimators=200, n_jobs=1, nthread=None,\n",
       "                               objective='multi:softprob', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=None, silent=None, subsample=1,\n",
       "                               verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_pipe = Pipeline(\n",
    "    [('tfidf', tfidf),\n",
    "     ('xgb', xgb)])\n",
    "\n",
    "xgb_pipe_params = {\n",
    "    \"tfidf__ngram_range\": [(1, 2)],\n",
    "    \"tfidf__max_features\": [2000, 3000, 4000],\n",
    "    \"tfidf__max_df\": [.5, .6, .7, .75],\n",
    "    \"tfidf__use_idf\": [True],\n",
    "    \"tfidf__norm\": [\"l2\"],\n",
    "    \"xgb__hidden_layer_sizes\": [10, 25, 50],\n",
    "    \"xgb__n_estimators\": [50, 100, 200],\n",
    "    \"xgb__max_depth\": [5, 10, 20]\n",
    "}\n",
    "\n",
    "\n",
    "xgb_model = GridSearchCV(xgb_pipe, param_grid=xgb_pipe_params, cv=2, verbose=2, n_jobs=-1)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(f'Train Score: {xgb_model.score(X_train, y_train)}')\n",
    "print(f'Test Score: {xgb_model.score(X_test, y_test)}')\n",
    "xgb_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  2.2min\n",
      "/Users/chris/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=-1)]: Done 648 out of 648 | elapsed: 26.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9870093588490012\n",
      "Test Score: 0.8722245496439045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.8, max_features=5000,\n",
       "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=frozenset({'a', 'about', 'above',\n",
       "                                                       'across', 'after',\n",
       "                                                       'afterward...\n",
       "                                                                      ccp_alpha=0.0,\n",
       "                                                                      class_weight=None,\n",
       "                                                                      criterion='gini',\n",
       "                                                                      max_depth=None,\n",
       "                                                                      max_features='auto',\n",
       "                                                                      max_leaf_nodes=None,\n",
       "                                                                      max_samples=None,\n",
       "                                                                      min_impurity_decrease=0.0,\n",
       "                                                                      min_impurity_split=None,\n",
       "                                                                      min_samples_leaf=1,\n",
       "                                                                      min_samples_split=2,\n",
       "                                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                                      n_estimators=200,\n",
       "                                                                      n_jobs=None,\n",
       "                                                                      oob_score=False,\n",
       "                                                                      random_state=None,\n",
       "                                                                      verbose=0,\n",
       "                                                                      warm_start=False),\n",
       "                                     n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onevrest = OneVsRestClassifier(RandomForestClassifier())\n",
    "\n",
    "onevrest_pipe = Pipeline(\n",
    "    [('tfidf', tfidf),\n",
    "     ('onevrest', onevrest)])\n",
    "\n",
    "\n",
    "onevrest_pipe_params = {\n",
    "    \"tfidf__ngram_range\": [(1, 2)],\n",
    "    \"tfidf__max_features\": [4500, 5000, 5500],\n",
    "    \"tfidf__max_df\": [.75, .8, .85],\n",
    "    \"tfidf__use_idf\": [True],\n",
    "    \"tfidf__norm\": [\"l2\"],\n",
    "    \"onevrest__estimator__n_estimators\": [200, 300] \n",
    "}\n",
    "\n",
    "\n",
    "onevrest_model = GridSearchCV(onevrest_pipe, param_grid=onevrest_pipe_params, cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "onevrest_model.fit(X_train, y_train)\n",
    "print(f'Train Score: {onevrest_model.score(X_train, y_train)}')\n",
    "print(f'Test Score: {onevrest_model.score(X_test, y_test)}')\n",
    "onevrest_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train Score: 0.9870093588490012\n",
    "Test Score: 0.8722245496439045"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions != y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model is GridSearchCV\n",
    "# best_estimator is Pipeline\n",
    "# named_steps is the steps in the pipeline\n",
    "# count_vec is the FITTED \n",
    "\n",
    "features_data = model.named_steps.cv.transform(X_train).toarray()\n",
    "features_columns = model.named_steps.cv.get_feature_names()\n",
    "features_df = pd.DataFrame(data=features_data, columns=features_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CHECK ### does this function work with tfidf, or just count vec?\n",
    "def plot_most_common(df, features_df, subreddit_list=subreddit_list, num_features=20, standardize=False, include_combined=False):\n",
    "    '''\n",
    "    Plots the most common features for each subreddit in the DataFrame\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    df: original DataFrame\n",
    "\n",
    "    features_df: should be output from transformer on df\n",
    "\n",
    "        Example:\n",
    "        features_df = pd.DataFrame(\n",
    "                                data={transformer}.transform(X).toarray(),\n",
    "                                columns={transformer}.get_feature_names())\n",
    "\n",
    "    num_features: number of most common features to plot for each subreddit\n",
    "\n",
    "    standardize: put all of the plots on the same scale\n",
    "\n",
    "    combined: include a plot of the most common features of all of the subreddits combined\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    plots\n",
    "\n",
    "    '''\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=1,\n",
    "                           nrows=len(subreddit_list) + int(1 if include_combined else 0),\n",
    "                           figsize=(15, num_features/1.3*len(subreddit_list)))\n",
    "\n",
    "    for subplot_idx, sub in enumerate(subreddit_list):\n",
    "        sub_features = features_df.loc[df['subreddit'] == sub]\n",
    "        sub_top_words = sub_features.sum().sort_values(ascending=False).head(num_features)[::-1]\n",
    "        sub_top_words.plot(kind='barh', ax=ax[subplot_idx])\n",
    "        ax[subplot_idx].set_title(f'{num_features} Most Common Words for {sub.upper()}', fontsize=16)\n",
    "        \n",
    "        if standardize:\n",
    "            max_occurence = features_df.sum().max()*1.02\n",
    "            ax[subplot_idx].set_xlim(0, max_occurence)\n",
    "\n",
    "    if include_combined:\n",
    "        most_common = features_df.sum().sort_values(ascending=False).head(num_features)[::-1]\n",
    "        most_common.plot(kind='barh', ax=ax[subplot_idx+1])\n",
    "        ax[subplot_idx+1].set_title(f'{num_features} Most Common Words for ({\", \".join(subreddit_list).upper()})')\n",
    "        \n",
    "        if standardize:\n",
    "            ax[subplot_idx+1].set_xlim(0, max_occurence)\n",
    "    \n",
    "    plt.tight_layout(h_pad=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_most_common(df, features_df, num_features=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###HELP### I don't think this is working right\n",
    "###HELP### coefficients don't make sense for the entire dataset, would need to do one for each thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###NOTE### coefficients only for lr and etc etc etc...\n",
    "###NOTE### coefficients only for two subreddits\n",
    "\n",
    "### FIX ### look at the coef_ portion of the new single model instead of the gridsearch\n",
    "\n",
    "\n",
    "# [-1][1] for last step (estimator)(instantiation)\n",
    "# coef_[0]because I don't know why\n",
    "coefs = model.best_estimator_.steps[-1][1].coef_[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.title('Feature Importance (Coefficients)', fontsize=20)\n",
    "plt.ylabel('Features', fontsize=18)\n",
    "plt.xlabel('(Abs) Coefficients', fontsize=18)\n",
    "\n",
    "coef_df = pd.DataFrame(data=[coefs], columns=features_columns).T\n",
    "coef_df['abs_coef'] = coef_df[0].abs()\n",
    "coef_df.sort_values('abs_coef', ascending=False)[0].head(15).plot(kind='barh');\n",
    "\n",
    "# coef_kill = coef_df.sort_values('abs_coef', ascending=False)[0].head(500).index\n",
    "\n",
    "# coef_kill\n",
    "\n",
    "\n",
    "# my_stops.extend(coef_kill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(subreddit_list):\n",
    "    '''\n",
    "    Makes combination pairs of subreddits from subreddit_list\n",
    "    '''\n",
    "    if len(subreddit_list) > 2:\n",
    "            return list(combinations(subreddit_list, 2))\n",
    "    return subreddit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = make_pairs(subreddit_list)\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_most_common_pairs(df, features_df, pairs, num_features=20):\n",
    "    '''\n",
    "    Plots the most common features for each subreddit in the DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    df: original DataFrame\n",
    "    \n",
    "    features_df: should be output from transformer on df\n",
    "        \n",
    "        Example:\n",
    "        features_df = pd.DataFrame(\n",
    "                                data={transformer}.transform(X).toarray(),\n",
    "                                columns={transformer}.get_feature_names())\n",
    "    \n",
    "    num_features: number of most common features to plot for each subreddit\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    plots\n",
    "    \n",
    "    '''\n",
    "    fig, ax = plt.subplots(ncols=2, \n",
    "                           nrows=len(pairs), \n",
    "                           figsize=(16,num_features/3*len(pairs)))\n",
    "\n",
    "    for i, pair in enumerate(pairs):\n",
    "\n",
    "        # features for each pair\n",
    "        feats_0 = features_df.loc[(df['subreddit'] == pair[0])]\n",
    "        feats_1 = features_df.loc[(df['subreddit'] == pair[1])]\n",
    "        # combined\n",
    "        common_feats = feats_0.append(feats_1)\n",
    "        # this is the most common between the two\n",
    "        most_common = common_feats.sum().sort_values(ascending=False).head(num_features)[::-1]\n",
    "        # plot\n",
    "        feats_0[most_common.index].sum().plot.barh(ax=ax[i, 0], color='navy')\n",
    "        feats_1[most_common.index].sum().plot.barh(ax=ax[i, 1], color='orange')\n",
    "        ax[i, 0].set_title(f'Top {num_features} - {pair} \\nSub: {pair[0].upper()}', fontsize=16, wrap=True)\n",
    "        ax[i, 1].set_title(f'Top {num_features} - {pair} \\nSub: {pair[1].upper()}', fontsize=16, wrap=True)\n",
    "        max_occurence = common_feats.sum().max()*1.02\n",
    "        ax[i, 0].set_xlim(0,max_occurence)\n",
    "        ax[i, 1].set_xlim(0,max_occurence)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_most_common_pairs(df, features_df, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = features_df.sum().sort_values(ascending=False).head(20)[::-1]\n",
    "groups = features_df.groupby(df['subreddit']).sum()[most_common.index].T.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, figsize=(18,20))\n",
    "\n",
    "groups.plot.bar(ax=ax[0], width=.8, fontsize=15)\n",
    "ax[0].set_title('20 Most Common Words', fontsize=20)\n",
    "ax[0].set_ylabel('# of Occurences', fontsize=15)\n",
    "ax[0].legend(fontsize=15, fancybox=True, framealpha=1, shadow=True, borderpad=1)\n",
    "\n",
    "groups.plot(kind='bar', ax=ax[1], width=.35, fontsize=15, stacked=True)\n",
    "ax[1].set_title('20 Most Common Words', fontsize=20)\n",
    "ax[1].set_ylabel('# of Occurences', fontsize=15)\n",
    "ax[1].legend(fontsize=15, fancybox=True, framealpha=1, shadow=True, borderpad=1)\n",
    "\n",
    "\n",
    "plt.tight_layout(h_pad=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(cm, columns=subreddit_list, index=subreddit_list)\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.set(font_scale=2)\n",
    "sns.heatmap(df_cm, annot=True, fmt=\"d\", cbar=False, cmap='Greens', ax=ax, )\n",
    "fontdict={'fontsize': 16}\n",
    "ax.set_yticklabels(labels=subreddit_list, rotation='horizontal', fontdict=fontdict)\n",
    "ax.set_xticklabels(labels=subreddit_list, rotation=20, fontdict=fontdict)\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position('top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcm = multilabel_confusion_matrix(y_test, y_pred)\n",
    "mtn = mcm[:, 0, 0]\n",
    "mtp = mcm[:, 1, 1]\n",
    "mfn = mcm[:, 1, 0]\n",
    "mfp = mcm[:, 0, 1]\n",
    "print(mcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=len(subreddit_list),\n",
    "                       figsize=(12, 6*len(subreddit_list)))\n",
    "\n",
    "for i, cm in enumerate(mcm):\n",
    "    df_cm = pd.DataFrame(cm)\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "    sns.heatmap(df_cm, annot=True, fmt=\"d\", cbar=False,\n",
    "                cmap='Purples', ax=ax[i, 0])\n",
    "\n",
    "    ax[i, 0].set_yticklabels(labels=[1, 0], rotation='horizontal')\n",
    "    ax[i, 0].set_xticklabels(labels=[1, 0])\n",
    "    ax[i, 0].xaxis.tick_top()\n",
    "    ax[i, 0].xaxis.set_label_position('top')\n",
    "    ax[i, 0].set_title(subreddit_list[i].upper())\n",
    "\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specif = tn / (tn + fp)\n",
    "\n",
    "    sens = tp / (tp + fn)\n",
    "    box_text = f'''Subreddit: {subreddit_list[i].upper()}\\n\\nSpecificity: {round(specif,4)}\\n\\nSensitivity: {round(sens,4)}'''\n",
    "    ax[i, 1].text(0.5, 0.5, box_text, horizontalalignment='center',\n",
    "                  verticalalignment='center', fontsize=24)\n",
    "    ax[i, 1].set_axis_off()\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, digits=3, target_names=subreddit_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TODO:</h1>\n",
    "\n",
    "1. Make it have the roc for each sub, have to get into the original df where subname equals indexes?\n",
    "2. Plot confusion matrix\n",
    "3. Make a notebook to test the confusion matrixes one by one with each individual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df = pd.DataFrame(y_prob, columns=subreddit_list)\n",
    "prob_df.round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_test, y_pred, multi_class='ovr')\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not multiclass\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {auc})', color='r', marker='D')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)', size=16)\n",
    "plt.ylabel('True Positive Rate (Sensitivity)', size=16)\n",
    "plt.title('ROC Curve', size=20)\n",
    "plt.legend(fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_roc_curve(lr, X_text, y_test)\n",
    "plot_roc_curve(dt, X_test, y_test, ax=disp.ax_);\n",
    "plot_roc_curve(dt, X_test, y_test, ax=disp.ax_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.random.normal(0, 0.8, 1000) x2 = np.random.normal(-2, 1, 1000) x3 = np.random.normal(3, 2, 1000)\n",
    "kwargs = dict(histtype='stepfilled', alpha=0.3, normed=True, bins=40)\n",
    "plt.hist(x1, **kwargs) plt.hist(x2, **kwargs) plt.hist(x3, **kwargs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create figure.\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "# Create histogram of observations.\n",
    "plt.hist(probs, bins=25, color='b')\n",
    "\n",
    "# Label axes.\n",
    "plt.title('Distribution of P(Outcome = 1)', fontsize=22)\n",
    "plt.ylabel('Frequency', fontsize=18)\n",
    "plt.xlabel('Predicted Probability that Outcome = 1', fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure.\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "# Create two histograms of observations.\n",
    "hst0 = plt.hist(probs[y_test == 0],\n",
    "         bins=25,\n",
    "         color='b',\n",
    "         alpha = 0.6,\n",
    "         label='Technology',)\n",
    "\n",
    "hst1 = plt.hist(probs[y_test == 1],\n",
    "         bins=25,\n",
    "         color='orange',\n",
    "         alpha = 0.6,\n",
    "         label='Science')\n",
    "\n",
    "# Add vertical line at P(Outcome = 1) = 0.5.\n",
    "plt.vlines(x=0.5,\n",
    "           ymin = 0,\n",
    "           ymax = max(hst1[0].max(), hst0[0].max()), # Max of the two highest respective hist values\n",
    "           color='r',\n",
    "           linestyle = '--')\n",
    "\n",
    "# Label axes.\n",
    "plt.title('Distribution of P(Science)', fontsize=22)\n",
    "plt.ylabel('Frequency', fontsize=18)\n",
    "plt.xlabel('Predicted Probability', fontsize=18)\n",
    "\n",
    "# Create legend.\n",
    "plt.legend(fontsize=20);\n",
    "\n",
    "# Thanks to Matt Brems for the colorful graphs! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
